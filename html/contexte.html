<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="utf-8">
    <title>Contexte</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name='author' content="Faouzi Mohamed">
    <meta name="keywords" content="classification, deep-learning, intelligence artificiel, machine learning, dataset">
    <meta name="color-scheme" content="dark light">
    <meta name='description' content="Explication des relation entre l'intelligence artificielle et la classification
 automatiques des images ainsi que des règle utiles à utiliser" />
    <script>
        MathJax = {
            tex: {
                inlineMath: [
                    ['$', '$'],
                    ['\\(', '\\)']
                ]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <!--<script id="MathJax-script" async src="../mathjax/es5/tex-svg-full.js"></script>-->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <link rel="stylesheet" type="text/css" href="../css/style.css">
    <noscript>
        <link rel="stylesheet" href="../css/noscript.css" />
    </noscript>

</head>

<body>
    <span id="top"></span>
    <nav id='header-nav'>
        <div id="menu-icon-wrapper">
            <i class="fas fa-bars fa-3x"></i>
        </div>
        <ul id="main-list">
            <li>
                <a href="../index.html">
                    <i id="home" class="fas fa-home"></i>
                    <span class="li-label">Acceuil</span>
                </a>
            <li>
                <a href="../html/contexte.html">
                    <i class="fas fa-wallet"></i>
                    <span class="li-txt">Contexte</span>
                </a>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-layer-group"></i>
                    <span class="li-txt">Deep learning</span>
                </button>
                <ul class="submenu">
                    <li><a href="../html/nn.html">Réseaux de neurones</a></li>
                    <li><a href="../html/cnn.html">Réseaux de neurones convolutionnels</a></li>
                </ul>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-file-download"></i>
                    <span class="li-txt">Télécharger</span>
                </button>
                <ul class="submenu">
                    <li>
                        <a href="#">Le contenu du site en pdf</a>
                    </li>
                </ul>
            </li>
        </ul>
        <label id="switch" class="switch">
            <input type="checkbox" id="slider">
            <span class="slider round"></span>
        </label>
        <a href="#" id="github">
            <i class="fab fa-github"></i>
        </a>
    </nav>
    <!--Main content-->
    <main>
        <aside id="left-aside">
            <nav id="aside-nav">
                <h1>Plan du site</h1>
                <ul id="ul-aside-nav"></ul>
            </nav>
        </aside>
        <article class="main-article" role="doc-chapter">
            <header>
                <h1>La classifcation des images</h1>

            </header>

            <section class="main-section" role="doc-introduction">
                <h2>L'intelligence artificiel</h2>
                <section>
                    <h3>Contexte et apprentissage</h3>
                    <p>
                        L'intelligence artificielle on en parle depuis plus de 50 ans maintenant. L'histoire du domaine
                        est
                        un peu agitée et bruyante. Ça a commencé par une période de grand enthousiasme où on s'imaginait
                        qu'on
                        arriverait très vite à faire des choses assez incroyables. Puis ça a été suivi par une période
                        un peu plus
                        sombre de désillusion où on a finalement constaté qu'on avait un peu sous-estimé les
                        difficultés. Dans les
                        années 90, le domaine a subi une renaissance sous le nom « machine learning ou apprentissage
                        automatique
                        en français ». Le machine learning c’est un domaine de l’intelligence artificiel qui étudie
                        comment des
                        algorithmes peuvent apprendre en se basant sur "des exemples". Et le « deep learning ou
                        apprentissage
                        profond » en est une manière particulière pour faire du machine learning. Celui-ci, pousse cet
                        apprentissage
                        encore plus profond pour pouvoir grossièrement s’approcher de l’intelligence humaine.
                    </p>
                    <p>
                        L’idée folle de faire du deep learning a été rejetée depuis longtemps car a priori elle ne
                        pouvait pas
                        fonctionner. Mais Il y a eu quand même des gens qui ont voulu essayer. Un de ces pionniers,
                        c'est un
                        français qui s'appelle Yann Le Cun. Celui-ci a développé un type de réseau de neurone
                        particulier qui
                        s’appelle « le réseau de neurone convolutionnel (CNN) ». Ces réseaux sont une forme particulière
                        de réseau
                        neuronal multicouche dont l’architecture des connexions est inspirée de celle du cortex visuel
                        des
                        mammifères. Par exemple, chaque élément n’est connecté qu’à un petit nombre d’éléments voisins
                        dans la
                        couche précédente. En 1995, Yan le Cun et deux autres ingénieurs ont développé un système
                        automatique
                        de lecture de chèques qui a été déployé largement dans le monde. À la fin des années 90, ce
                        système lisait
                        entre 10 et 20 % de tous les chèques émis aux États-Unis. Mais ces méthodes étaient plutôt
                        difficiles à
                        mettre en œuvre avec les ordinateurs de l’époque, et malgré ce succès, les réseaux
                        convolutionnels et les
                        réseaux neuronaux plus généralement ont été délaissés par la communauté de la recherche entre
                        1997 et
                        2012.
                    </p>
                </section>
                <section>
                    <h3>La période de renaissance</h3>
                    <p>
                        Depuis 2010, l’intelligence artificiel connaît toutefois un nouvel essor du fait,
                        principalement, de
                        l’amélioration considérable de la puissance de calcul des ordinateurs et d’un accès à des
                        quantités massives
                        de données. Ce dernier a permis de pouvoir utiliser des algorithmes de classification d’images
                        et de
                        reconnaissance d’un chat par exemple, il fallait auparavant réaliser soi-même un
                        échantillonnage.
                        Aujourd’hui, une simple recherche sur Google permet d’en trouver des millions. Ensuite la
                        découverte de
                        la très grande efficacité des processeurs de cartes graphiques des ordinateurs pour accélérer le
                        calcul des
                        algorithmes d’apprentissage. Le processus étant très itératif, cela pouvait prendre des semaines
                        avant 2010
                        pour traiter l’intégralité d’un échantillonnage. La puissance de calcul de ces cartes, (capables
                        de plus de
                        mille milliards d’opérations par seconde) a permis un progrès considérable pour un coût
                        financier restreint
                        (moins de 1000 euros la carte)
                    </p>
                    <p>
                        Parmi les techniques d’apprentissage machine (machine learning), c’est celle de l’apprentissage
                        profond qui paraît la plus prometteuse pour un certain nombre d’application (dont la
                        reconnaissance de voix
                        ou d’images). En effet dès 2003 des expériences sont menées simultanément par Microsoft, Google
                        et IBM
                        avec l’aide du laboratoire de Toronto de Hinton qui ont montré que les réseaux profonds
                        pouvaient diminuer
                        de moitié les taux d’erreurs des systèmes de reconnaissance vocale. Et le fait que plusieurs
                        records en
                        reconnaissance d’image ont été obtenus par des algorithmes basées sur des réseaux de neurones
                        convolutionnels.
                    </p>
                    <p>
                        La diminution des taux d’erreurs était telle une véritable révolution que du jour au lendemain,
                        la
                        majorité des équipes de recherche en parole et en vision ont abandonné leurs méthodes préférées
                        et sont
                        passées aux réseaux de neurones convolutionnels et autres réseaux neuronaux. L’industrie
                        d’Internet a
                        immédiatement saisi l’opportunité et a commencé à investir massivement dans des équipes de
                        recherche et
                        développements en apprentissage profond.
                    </p>
                </section>
            </section>

            <section class="main-section">
                <details open>
                    <summary>
                        <h2>Notions de base</h2>
                    </summary>
                    <section>
                        <h3>Définition d’une image (Numérique)</h3>
                        <p>
                            Une image numérique est une figure (dessin, icône, photographie...) créée, traitée, stockée
                            sous
                            forme binaire (suite de 0 et de 1). On distingue 2 types d’image numérique : Les images
                            <a href="#vectorielle"><em class="bold">vectorielles</em></a> et les images <a
                                href="#matricielle"><em class="bold">matricielles</em></a>. Dans notre travail nous
                            utiliserons des images matricielles pour faire
                            de la classification.
                        </p>

                        <section id="vectorielle">
                            <h4>Les images vectorielles</h4>
                            <p>
                                Une image vectorielle en informatique, est une image numérique composée d’objets
                                géométriques
                                individuels (segments de droite, polygones, arcs de cercle, etc.) définis chacun par
                                divers attributs de forme,
                                de position, de couleur, etc. (définis de manière mathématique). Ces images sont
                                utilisées pour réaliser des
                                schémas ou des plans mais pas exclusivement. Pour les images vectorielles on ne parle
                                pas de Définition ni
                                de Résolution à proprement parlé. Il n’y a que quand on transforme ces images
                                vectorielles en images
                                matricielles que ces notions rentrent en compte. Ils présentent 2 avantages : elles
                                occupent peu de place en
                                mémoire et peuvent être redimensionnées sans perte d’informations et sans effet dit :
                                d’escalier (crénelage).
                            </p>
                        </section>
                        <section id="matricielle">
                            <h4>Les images matricielles</h4>
                            <p>
                                Une image matricielle est une représentation planaire d’une scène ou d’un objet situé en
                                général dans un
                                espace tridimensionnel. Lorsqu'on agrandit une image matricielle, on voit que celle-ci
                                est composée d'un
                                ensemble de "points", appelés <strong class="bold">pixels</strong>.
                            </p>

                            <div class="figure-layout">
                                <figure id="ex-matriciel">
                                    <img src="../img/matrix-img.svg" alt="Images matriciel"
                                        title="Illustration de l’ensemble de point sur un image">
                                    <figcaption>Illustration de l’ensemble de point sur un image matricielle
                                    </figcaption>
                                </figure>
                            </div>
                        </section>
                    </section>
                    <section>
                        <h3>Caractéristiques d’une image matricielle</h3>
                        <p>
                            Une image matricielle est caractérisée essentiellement de ses pixels, sa définition et sa
                            résolution. En effet,
                            une image numérique est un fichier informatique pouvant être vu comme un tableau de nombres.
                        </p>
                        <ul>
                            <li><strong class="bold">Le pixel</strong> représente ainsi le plus petit élément
                                constitutif d’une image numérique.
                                L’ensemble de
                                ces pixels est contenu dans un tableau à deux dimensions constituant l’image.
                            </li>
                            <li>Sa <strong class="bold">définition</strong> est le nombre total de points (pixels)
                                qui constituent l’image : C’est
                                le nombre
                                de colonnes (largeur) de l’image que multiplie son nombre de lignes (longueur) qui
                                sont en réalité
                                ses dimensions.
                            </li>
                        </ul>

                        <div class="figure-layout">
                            <figure id="ex-pixels">
                                <img src="../img/img_pixels.svg" alt="Image en pixel - resolution"
                                    title="Cliquez pour zoomer" />
                                <figcaption>Exemple d’une image de résolution $11×12$</figcaption>
                            </figure>
                        </div>

                        <p>
                            Et bien sa résolution est le nombre de pixels contenus dans l'image par unité de
                            longueur. La résolution
                            définit la netteté et la qualité d'une image. Plus la densité des pixels constituant
                            l’image matricielle est
                            élevée, plus les points sont nombreux, plus votre image est précise dans les détails. La
                            résolution permet
                            ainsi d'établir le rapport entre la définition en pixels d'une image et la dimension
                            réelle de sa représentation
                            sur un support physique (affichage écran, impression papier...). On l’écrit souvent de
                            la manière
                            largeur × hauteur.(voire légende du figure précédente).
                        </p>

                        <div class="figure-layout slide-container">
                            <figure id="ex-resol1">
                                <img src="../img/ex0-resolution.svg"
                                    alt="Image dune voiture sur différentes résolution">
                                <figcaption class=" caption-text">
                                    Image dune voiture sur différentes résolution
                                </figcaption>
                            </figure>
                            <figure id="ex-resol2">
                                <img src="../img/ex1-resolution.svg" alt="Image dune femme sur différentes résolution">
                                <figcaption class=" caption-text">Image dune femme sur différentes résolution
                                </figcaption>
                            </figure>
                        </div>
                    </section>

                    <section>
                        <h3>La profondeur des couleurs</h3>
                        <p>
                            En plus de sa définition, une image matricielle utilise plus ou moins de mémoire selon le
                            codage
                            des informations de couleur qu’elle possède. C’est ce que l’on nomme le codage de couleurs
                            ou profondeur
                            des couleurs, exprimé en bit par pixel (<span class="bold">bpp</span>) : 1, 4, 8, 16 bits.
                            Plus elle est importante,
                            plus l'image peut
                            afficher de couleurs différentes. Elle est comprise entre 1 et 32 bits.
                        </p>
                        <section>
                            <h4>Codage d'une image en noir et blanc</h4>
                            <p>
                                Pour ce type de codage, chaque pixel est soit noir, soit blanc. Il faut donc un bit pour
                                coder un pixel
                                0 pour noir, 1 pour blanc. Ce type de codage est économe en mémoire, il convient pour un
                                plan ou un texte
                                mais on voit rapidement ses limites lorsqu'il s'agit d'une photographie.
                            </p>
                        </section>

                        <section>
                            <h4>Codage d'une image en niveaux de gris</h4>
                            <p>
                                Si on code chaque pixel sur deux bits, on aura 4 possibilités : noir, gris foncé, gris
                                clair, blanc.
                                L'image sera très peu nuancée mais plus que le noir et blanc. En général on code chaque
                                pixel sur 8 bits =
                                1 octet. On a alors 256 niveaux de gris (possibilités). L'image codée de 10000 pixels
                                occupe alors 10000
                                octets en mémoire.
                            </p>
                        </section>

                        <section>
                            <h4>Codage d’une image en couleurs 8 bits</h4>
                            <p>
                                Dans ce cas on attache une palette de 28 = 256 couleurs à l'image. Chaque code (de 0 à
                                255) désigne
                                une couleur choisie parmi les 16 millions de couleurs de la palette <abbr
                                    title="Rouge Bleu Vert">RVB</abbr> (voir ci-après) de manière
                                pertinente ; c’est à dire qu’un programme recherche les couleurs les plus adaptées.
                                Ainsi chaque pixel est
                                codé sur 8 bits = 1 octet, donc l’image codée de 10000 pixels occupe 10000 octets en
                                mémoire (ou 80000
                                bits).
                            </p>
                        </section>

                        <section>
                            <h4>Codage d’une image en couleurs 24 bits</h4>
                            <p>
                                Dans ce cas, la couleur du pixel est codée sur la palette du mode <abbr
                                    title="Rouge Bleu Vert">RVB</abbr> (16 millions de couleurs).
                                Chaque pixel est codé 3 octets soit 24 bits ; par conséquent l’image codée de 10000
                                pixels occupe 30000
                                octets en mémoire. Ce type de codage très utilisé est gourmand en mémoire mais donne un
                                très bon rendu
                                d’image.
                            </p>
                        </section>

                        <section>
                            <h4>Le rendu des couleurs</h4>
                            <p>
                                Le rendu des couleurs d’une image matricielle peut être assuré par le codage
                                <em class="bold"><abbr title="Rouge Bleu Vert">RVB</abbr> 24 bits</em>. Pour chaque
                                pixel de l’image, un triplet de nombres donne le niveau d’intensité lumineuse des trois
                                sous-pixels rouge
                                vert bleu formant le pixel. En 24 bits, cela permet d’obtenir plus de 16 millions de
                                couleurs différentes.
                                Pour une image en niveaux de gris, un seul nombre est requis par pixel, les sous-pixels
                                recevant la même
                                information.
                            </p>
                        </section>
                    </section>

                    <section>
                        <h3>Le voisinage</h3>
                        <p>
                            Le plan de l’image est divisé en termes de formes rectangulaires ou hexagonales
                            permettant ainsi
                            l’exploitation de la notion de voisinage. Le voisinage d’un pixel est formé par
                            l’ensemble des pixels qui se
                            situent autour de ce même pixel. On définit aussi l’assiette comme étant l’ensemble de
                            pixels définissant le
                            voisinage pris en compte autour d’un pixel. On distingue deux types de voisinage :
                        </p>
                        <ul>
                            <li><em class="bold">Voisinage à 4</em> : On ne prend en considération que les pixels
                                qui ont un coté commun avec le pixel
                                considéré.
                            </li>
                            <li><em class="bold">Voisinage à 8</em> : On prend en compte tous les pixels qui ont au
                                moins un point en liaison avec le
                                pixel considéré.
                            </li>
                        </ul>

                        <div class="figure-layout slide-container black-arrow">
                            <div class="slide-content">
                                <figure id="ex-vois4">
                                    <img src="../img/voisinage_hex.svg" alt="Voisinage à 4">
                                    <figcaption class="caption-text">Voisinage à 4</figcaption>
                                </figure>
                                <figure id="ex-vois8">
                                    <img src="../img/voisinage_rect.svg" alt="Voisinage à 8">
                                    <figcaption class="caption-text">Voisinage à 8</figcaption>
                                </figure>
                            </div>
                        </div>
                    </section>

                    <section>
                        <h3>Luminescence</h3>
                        <p>
                            C’est le degré de luminosité des points de l’image. Elle est définie aussi comme étant
                            le quotient
                            de l’intensité lumineuse d’une surface par l’aire apparente de cette surface, pour un
                            observateur lointain, le
                            mot luminance est substitué au mot brillance, qui correspond à l’éclat d’un objet.
                        </p>
                        <p>Une bonne luminance se caractérise par :</p>
                        <ul>
                            <li>
                                Des images lumineuses (brillantes),
                            </li>
                            <li>
                                Un bon contraste : il faut éviter les images où la gamme de contraste tend vers le
                                blanc ou le noir.
                                Ces images entraînent des pertes de détails dans les zones sombres ou lumineuses.
                            </li>
                            <li>
                                L’absence de parasites.
                            </li>
                        </ul>
                    </section>

                    <section>
                        <h3>Bruit</h3>
                        <p>
                            Un bruit (parasite) dans une image est considéré comme un phénomène de brusque variation
                            de
                            l’intensité d’un pixel par rapport à ses voisins, il provient de l’éclairage des
                            dispositifs optiques et
                            électroniques du capteur. C’est un parasite qui représente certains défauts (poussière,
                            petits nuages, baisse
                            momentanée de l’intensité électrique sur les capteurs, ...etc.). Il se traduit par des
                            taches de faible dimension
                            et dont la distribution sur l’image est aléatoire. Nous verrons plus tard comment on
                            peut les diminuer, voir
                            les éliminer en utilisant les convolutions.
                        </p>
                        <p>
                            Pour trouver donc les filtres dans une images, nous utiliserons des <q class="quotation">
                                convolutions </q> et
                            ce qu’on appelle <q class="quotation"> Pooling </q>.
                        </p>
                    </section>

                    <section>
                        <h3>Contours</h3>
                        <p>
                            Les contours représentent la frontière entre les objets de l’image, ou la limite entre
                            deux pixels dont
                            les niveaux de gris représentant une différence significative. Dans une image numérique,
                            les contours se
                            situent entre les pixels appartenant à des régions ayant des intensités moyennes
                            différentes ; il s’agit de
                            contours de type <q> saut d’amplitude </q>. Un contour peut également correspondre à une
                            variation locale
                            d’intensité présentant un maximum ou un minimum ; il s’agit alors de contour <q
                                class="quotation"> en toit </q>.
                            Ces contours on peut les détecter sur une image en appliquant un filtre sur ce dernier.
                        </p>
                    </section>

                    <section>
                        <h3>Filtrage d’une image par convolutions</h3>
                        <p>
                            Le filtrage d'une image numérique permet de modifier son spectre spatial. On peut par
                            exemple
                            chercher à atténuer les hautes fréquences pour la rendre moins nette, à réduire le
                            bruit, ou au contraire à
                            accentuer les hautes fréquences pour accentuer la netteté. La dérivation est aussi une
                            opération de filtrage,
                            employée pour la détection des bords.
                        </p>
                    </section>
                </details>
            </section>

            <section class="main-section">
                <h2>La classification automatique</h2>
                <section>
                    <h3>Objectif et motivations</h3>
                    <p>
                        L’objectif de la classification d’images est d’élaborer un système capable d’affecter une classe
                        automatiquement à une image. Ainsi, ce système permet d’effectuer une tâche d’expertise qui peut
                        s’avérer
                        couteuse à acquérir pour un être humain en raison notamment de contraintes physiques comme la
                        concentration, la fatigue ou le temps nécessité par un volume important de données images.
                    </p>

                    <div class="figure-layout">
                        <figure id="contraintes">
                            <img src="../img/contraintes.svg" alt="contraintes physiques">
                            <figcaption>Contraintes physiques</figcaption>
                        </figure>
                    </div>
                    <p>
                        Les applications de la classification automatique d’images sont nombreuses et le point commun à
                        toutes
                        ces applications est qu’elles nécessitent la mise en place d’une chaîne de traitement à partir
                        des images
                        disponibles composées de plusieurs étapes afin de fournir en sortie une décision. Chaque étape
                        de la mise
                        en place d’un tel système de classification nécessite la recherche de méthodes appropriées pour
                        une
                        performance globale optimale à savoir la phase d’extraction de caractéristiques et la phase
                        d’apprentissage.
                    </p>
                    <p>
                        Typiquement, nous disposons de données images desquelles il nous faut extraire des informations
                        pertinentes traduites sous formes de vecteurs numériques. Cette phase d’extraction nous permet
                        de travailler
                        dans un espace numérique. Il s’agit ensuite d’élaborer, dans la phase d’apprentissage, à partir
                        de ces données
                        initiales, une fonction de décision pour décider de l’appartenance d’une donnée nouvelle a l’une
                        des classes
                        en présences. La phase d’extraction de caractéristiques peut être précédée d’une phase dite de
                        pré-
                        traitement. Cette phase a pour but de nettoyer l’image, c’est-à-dire d’isoler le contenu
                        informatif ou d’intérêt
                        dans l’image. Cette opération permet ainsi d’occulter ou d’atténuer toute information
                        susceptible de nuire
                        à la description du contenu pertinent lors de la phase d’extraction de caractéristiques.
                    </p>
                    <p>
                        On retrouve la classification automatique sur divers domaines notamment sur des applications
                        dans
                        le domaine médical comme la reconnaissance de cellules, dans le domaine du document comme la
                        reconnaissance d’écriture manuscrite pour les chèques, les codes postaux, les cartes, dans le
                        domaine urbain
                        comme la reconnaissance de piétons, la détection de véhicules ; dans le domaine de la biométrie
                        comme la
                        reconnaissance de visage.
                    </p>
                </section>
                <section>
                    <h3>La classification supervisée</h3>
                    <section>
                        <h4>Objectif</h4>
                        <p>
                            L'objectif de la classification supervisée est principalement de définir des règles
                            permettant de
                            classer des objets dans des classes à partir de variables qualitatives ou quantitatives
                            caractérisant ces objets.
                            Elle est l'outil essentiel utilisé pour extraire des informations quantitatives à partir de
                            données d'images. Le
                            fait que pour l’humain, plusieurs facteurs peuvent l’empêcher de faire une classification,
                            il est nécessaire
                            de montrer à des algorithmes comment reconnaitre des objets et comment les classifier. Et
                            cette tâche est
                            ce qu’on appelle la phase d’apprentissage. Nous utiliserons un réseau de neurones
                            convolutionnels
                            (CNN) pour réaliser cet apprentissage.
                        </p>
                    </section>
                    <section>
                        <h4>Phase d'apprentissage</h4>
                        <p>
                            On dispose au départ d'un <strong>échantillon</strong> dit d'<strong>apprentissage</strong>
                            dont le classement est connu. Cet
                            échantillon est utilisé pour l'apprentissage des règles de classement.
                        </p>

                        <p>
                            La procédure est la suivante :
                        </p>
                        <ul>
                            <li>
                                On montre à un algorithme d’apprentissage automatique des objets à classifier en lui
                                donnant aussi
                                les étiquettes d’appartenance d’une classe pour chaque objet.
                            </li>
                            <li>
                                Cet algorithme va chercher tout seul les règles qui permettent de reconnaitre ces
                                objets pour bien
                                les classer.
                            </li>
                            <li>
                                Après cet étape, l’algorithme aura découvert les différentes caractéristiques des
                                objets et on pourra
                                lui donner d’autres objets qu’il n’a pas encore vu pour nous donner leur classe
                                d’appartenance.
                            </li>
                        </ul>
                    </section>
                    <section>
                        <h4>Jeu de données <strong lang="en">Dataset</strong></h4>
                        <p>
                            Alors, il est nécessaire d'étudier la fiabilité de ces règles. Pour évaluer une règle de
                            classement nous
                            pourrons nous pourrons séparer la phase d’apprentissage en plusieurs phase (diviser pour
                            mieux régner).
                            Pour ce faire nous allons rassembler nos données à classifier en une sorte de base de
                            données qu’on appelle
                            « jeu de donnée » connue sous le nom de « dataset en anglais ».
                        </p>
                        <p>
                            Un jeu de donnée (dataset) va contenir d’énorme quantité de donnée. En effet, plus notre
                            dataset sera grand
                            et diversifié, plus notre modèle sera apte par la suite à prédire des résultats les plus
                            justes possible.
                        </p>

                        <p>Le dataset doit être formaté de la façon suivante :</p>
                        <ul>
                            <li>
                                <span class="bold">Train set</span> :
                                Celui-ci va être le plus volumineux en termes de
                                donnée. En effet, c’est sur ce jeu ci que le réseau va itérer durant
                                la phase d’entrainement pour pouvoir s’approprier des
                                paramètres, et les ajuster au mieux. Certaines règles préconisent
                                qu’il soit composé de 80% des données disponibles. C’est la
                                phase d’apprentissage.
                            </li>
                            <li>
                                <span class="bold">Validation set</span> :
                                Quant à lui, on préconise d’avoir environ 10%
                                des données disponible. Ce jeu sera appelé une seule fois, à la
                                fin de chaque itération d’entrainement. Il va permettre
                                d’équilibrer le système. C’est la phase d’ajustage.
                            </li>
                            <li>
                                <span class="bold">Test set</span> :
                                Test set : Ce dernier va avoir un rôle bien différent des autres,
                                puisqu’il ne servira pas à ajuster notre réseau. En effet, il va
                                avoir pour rôle d’évaluer le réseau sous sa forme finale, et de
                                voir comment il arrive à prédire. C’est pour cela qu’il doit être
                                composé exclusivement de nouveaux échantillons, encore
                                jamais utilisé pour éviter de biaiser les résultats en lui envoyant
                                des donnés, qu’il connaîtrait déjà et qu’il aurait déjà appris lors
                                de la phase d’entrainement ou de validation. Celui-ci encore
                                peut être estimé de l’ordre de 10% des données disponible.
                            </li>
                        </ul>
                        <div id='fig' class="figure-layout">
                            <figure id="pie-chart">
                                <svg version="1.1" xmlns="http://www.w3.org/2000/svg"
                                    xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="50 0 700 800"
                                    enable-background="new 0 0 1000 1000" width="550" height='450'>
                                    <g clip-path="url(#clip0)" transform="translate(-718 -123)">
                                        <g clip-path="url(#clip10)" class='train-set'>
                                            <path d="M1133.71 274.228C1295.21 274.228 1426.21 
                                                405.23 1426.21 566.828 1426.21 728.427 1295.21 859.428 
                                                1133.61 859.428 972.008 859.428 841.007 728.427 
                                                841.007 566.828 841.007 536.124 845.839 505.611 855.327 
                                                476.41L1133.61 566.828Z" fill-rule="evenodd" />
                                        </g>
                                        <g clip-path="url(#clip11)" class="validation-set">
                                            <path d="M852.96 474.69C872.055 415.923 909.264 
                                                364.71 959.254 328.39L1131.24 565.109Z" fill-rule="evenodd" />
                                        </g>
                                        <g clip-path="url(#clip12)" class="test-set">
                                            <path d="M960.717 327.327C1010.71 291.007 1070.91 
                                                271.445 1132.7 271.445L1132.7 564.046Z" fill-rule="evenodd" />
                                        </g>
                                        <g clip-path="url(#clip13)" class='train-set'>
                                            <text font-family="Calibri,Calibri_MSFontService,sans-serif"
                                                font-weight="700" font-size="29" transform="translate(1321.56 844)">
                                                Train set
                                                <tspan y='1cm' x='1.1cm'>80%</tspan>
                                            </text>
                                        </g>

                                        <g clip-path="url(#clip15)" class="validation-set">
                                            <text font-family="Calibri,Calibri_MSFontService,sans-serif"
                                                font-weight="700" font-size="29" transform="translate(775.776 320)">
                                                Validation
                                                <tspan y='1cm' x='0.5cm'>set 10%</tspan>
                                            </text>
                                        </g>
                                        <g clip-path="url(#clip18)" class="test-set">
                                            <text font-family="Calibri,Calibri_MSFontService,sans-serif"
                                                font-weight="700" font-size="29" transform="translate(939.77 228)">
                                                Test set
                                                <tspan y='1cm' x='1.1cm'>10%</tspan>
                                            </text>
                                        </g>
                                        <g clip-path="url(#clip20)" class="pie-chart-title">
                                            <text font-family="Times new roman,Calibri_MSFontService,sans-serif"
                                                font-weight="700" font-size="44" transform="translate(775.08 180)"
                                                align='center'>DIVISION DU JEU DE DONNÉES</text>
                                        </g>
                                    </g>
                                </svg>
                                <figcaption>Division du jeu de données en 3 groupes</figcaption>
                            </figure>
                        </div>
                    </section>
                </section>
            </section>

            <section class="main-section">
                <h2>Indicateur de performance</h2>
                <section>
                    <h3>Matrice de confusion</h3>
                    <p>
                        Une matrice de confusion est une matrice qui mesure la qualité d'un système de classification,
                        il
                        représente les performances d’un modèle de classification dans une matrice dite de confusion.
                        Chaque ligne
                        correspond à une classe réelle, chaque colonne correspond à une classe estimée. La cellule ligne
                        L, colonne
                        C contient le nombre d'éléments de la classe réelle L qui ont été estimés comme appartenant à la
                        classe C.
                    </p>
                    <p>
                        Un des intérêts de la matrice de confusion est qu'elle montre rapidement si un système de
                        classification
                        parvient à classifier correctement.
                    </p>
                    <p>
                        Prenons l’exemple d’un classifieur binaire, c’est-à-dire, qui prédit 2 classes notées classe
                        0 et classe
                        1. Pour mesurer les performances de ce classifieur, il est d’usage de distinguer 4 types
                        d’éléments classés
                        pour la classe voulue :
                    </p>
                    <ul class="align-left">
                        <li>
                            <strong>Vrai positif (VP)</strong> &nbsp;&nbsp;&nbsp;:
                            Elément de la classe 1 correctement prédit
                        </li>
                        <li>
                            <strong>Vrai Négatif (VN)</strong> &nbsp;:
                            Elément de la classe 0 correctement prédit
                        </li>
                        <li>
                            <strong>Faux positif (FP)</strong>&nbsp; &nbsp;:
                            Elément de la classe 0 correctement prédit
                        </li>
                        <li>
                            <strong>Faux Négatif (FN)</strong> :
                            Elément de la classe 0 correctement prédit
                        </li>
                    </ul>

                    <p>
                        Ces informations peuvent être rassemblés et visualisés sous forme de tableau dans une
                        matrice de confusion.
                        Dans le cas d’un classifieur binaire, on obtient :
                    </p>
                    <figure class="table-center center">
                        <figcaption>Matrice de confusion</figcaption>
                        <table>
                            <thead rowspan="2">
                                <tr>
                                    <td colspan="2" rowspan="2" class="empty"></td>
                                    <th scope="col" colspan="2">
                                        Classe prédite
                                    </th>
                                </tr>
                                <tr>
                                    <th scope="col">Classe 0</th>
                                    <th scope="col">Classe 1</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <th scope="row" id="rotate" rowspan="2">Classe réelle</th>
                                    <th scope="row">Classe 0</th>
                                    <td>VN</td>
                                    <td>FN</td>
                                </tr>
                                <tr>
                                    <th scope="row">Classe 1</th>
                                    <td>FP</th>
                                    <td>VP</td>
                                </tr>
                            </tbody>
                        </table>
                    </figure>

                    <section>
                        <h4>Exemple</h4>
                        <p>
                            Pour bien comprendre la notion de matrice de confusion, prenons cet exemple tiré sur
                            <a href="https://fr.wikipedia.org/wiki/Matrice_de_confusion#Exemple"
                                title="Exemple sur wikipedia">
                                Wikipédia</a>
                        </p>
                        <p class="alinea">
                            On souhaite mesurer la qualité d'un système de classification de courriers électroniques.
                            Les courriers sont
                            classifiés selon deux classes : courriel pertinent ou pourriel intempestif. Supposons que
                            notre classificateur
                            est testé avec un jeu de 200 mails, dont 100 sont des courriels pertinents et les 100 autres
                            sont des pourriels.
                        </p>
                        <p>Pour cela, on veut savoir :</p>
                        <ul>
                            <li>Combien de courriels seront faussement estimés comme des pourriels (fausses alarmes)
                                et</li>
                            <li>Combien de pourriels ne seront pas estimés comme tels et classifiés à tort comme
                                courriels.</li>
                        </ul>
                        <p>
                            La matrice de confusion suivante se lit alors comme suit :
                        </p>
                        <ul>
                            <li>
                                Horizontalement, sur les 100 courriels initiaux (i.e. : 95+5), 95 ont été estimés
                                par le système de
                                classification comme tels et 5 ont été estimés comme pourriels (i.e. : 5
                                faux-négatifs),
                            </li>
                            <li>
                                Horizontalement, sur les 100 pourriels initiaux (i.e. : 3+97), 3 ont été estimés
                                comme courriels
                                (i.e. : 3 faux-positifs) et 97 ont été estimés comme pourriels,
                            </li>
                            <li>
                                Verticalement, sur les 98 mails (i.e. : 95+3) estimés par le système comme
                                courriels, 3 sont en fait
                                des pourriels,
                            </li>
                            <li>
                                Verticalement, sur les 102 mails (i.e. : 5+97) estimés par le système comme
                                pourriels, 5 sont en fait
                                des courriels.
                            </li>
                            <li>
                                Diagonalement (du haut gauche, au bas droit), sur les 200 courriels initiaux, 192
                                (95 + 97) ont été
                                estimés correctement par le système.
                            </li>
                        </ul>
                        <p>
                            Ces informations peuvent être rassemblés et visualisés sous forme de tableau dans une
                            matrice de confusion.
                            Dans le cas d’un classifieur binaire, on obtient :
                        </p>
                        <figure class="table-center-2 center" id="fig-table-2">
                            <figcaption>Exemple de matrice de confusion</figcaption>
                            <table id="table-2">
                                <thead rowspan="2">
                                    <tr>
                                        <td colspan="2" rowspan="2" class="empty"></td>
                                        <th scope="col" colspan="2">
                                            Classe estimée par le classificateur
                                        </th>
                                    </tr>
                                    <tr>
                                        <th scope="col">Courriel</th>
                                        <th scope="col">Pourriel</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <th scope="row" id="rotate" rowspan="2">Classe réelle</th>
                                        <th scope="row">Courriel</th>
                                        <td>95 (vrais positifs)</td>
                                        <td>5 (faux négatifs)</td>
                                    </tr>
                                    <tr>
                                        <th scope="row">Pourriel</th>
                                        <td>3 (faux positifs)</th>
                                        <td>97 (vrais négatifs)</td>
                                    </tr>
                                </tbody>
                            </table>
                        </figure>
                        <p class="alinea">
                            Cette notion s'étend à un nombre quelconque de classes. On peut normaliser cette matrice
                            pour en simplifier
                            la lecture : dans ce cas, un système de classification sera d'autant meilleur que sa matrice
                            de confusion
                            s'approchera d'une matrice diagonale.
                        </p>
                        <p>
                            Notons que la matrice de confusion est aussi généralisable lorsqu’il y a k > 2 classes à
                            prédire (Nombre de classe). À partir de la matrice de confusion on peut dériver tout un tas
                            de critères de performance. De
                            manière générale, on préfère donner une fraction d'erreurs à un nombre total d'erreurs.
                            Voici quelques exemples de mesures de performance souvent utilisées :
                        </p>
                        <p>
                            La <strong>précision</strong>, c’est-à-dire la proportion de prédictions correctes parmi
                            les points que l’on a prédits positifs :
                            $$précision = {VP \over VP + FP}.$$
                        </p>
                        <p>
                            Rappel. Proportion d’éléments bien classés par rapport au nombre d’éléments de la classe
                            à prédire :
                            $$Rappel = {VP \over VP + FN}$$
                        </p>
                        <p>
                            F-mesure. Mesure de compromis entre précision et rappel :
                            $$F - mesure = 2×{Précision × Rapel \over Précision + Rapel}$$
                        </p>

                        <p>
                            Dans notre cas d'étude on va représenter les matrices de confusions de la manière suivante :
                        </p>
                        <p>
                            On pourrait avoir deux cas de figures :
                        </p>
                        <ul>
                            <li>
                                Une matrice dont la diagonale est très foncé (sombre) : Ce qui veut dire que le système
                                de classifcation
                                fait bien sont travail.
                            </li>
                            <li>
                                Une matrice dont la diagonale ne contient pas le maximum de couleur foncés: dans ce cas
                                il faut
                                revoir le système et modifier certains paramètres afin que cette matrice devien
                                diagonal.
                            </li>
                        </ul>

                        <div class="figure-layout slide-container dark-font">
                            <figure id="ex1-matrice-confusion">
                                <img src="../img/conf-matrix-1.svg" alt="Exemple d'une matrice de confusion diagonal">
                                <figcaption class="caption-text">Exemple d'une matrice de confusion diagonal
                                </figcaption>
                            </figure>
                            <figure id="ex2-matrice-confusion">
                                <img src="../img/conf-matrix-2.svg"
                                    alt="Exemple d'une matrice de confusion non diagonal">
                                <figcaption class="caption-text">Matrice de confusion non diagonal.</figcaption>
                            </figure>
                        </div>
                    </section>
                </section>
            </section>

            <section class="main-section">
                <h2>Classification automatique d'images et apprentissage machine</h2>
                <p>
                    A première vue, la classification des données ne semble pas difficile. Les humains sont bien
                    meilleurs que les machines pour comprendre le contexte des éléments à classifier. Cependant, à
                    mesure que
                    le nombre d’actifs, les niveaux et les règles de classification se développent, la classification
                    des données
                    se complique rapidement et les processus manuels se corrompent. Les méthodes manuelles se sont
                    avérées
                    très difficiles à appliquer pour des tâches en apparence très simples comme la classification des
                    images, la
                    reconnaissance d’objets dans les images ou la reconnaissance vocale. Les données venant du monde
                    réel
                    les échantillons d’un son ou les pixels d’une image sont complexes, variables et entachées de bruit.
                </p>
                <p>
                    Pour un ordinateur, les images ne sont que des tableaux de nombres ayant certaines caractéristiques
                    tels que la couleur, la luminosité de pixel chaque pixel. Nous, humains, pouvons lui montrer qu’il
                    peut s’en
                    servir de ces pixels pour identifier des objets sur l’image et donc de pouvoir reconnaitre ce qui se
                    trouve
                    sur l’image.
                </p>
                <p>
                    Comment une machine peut-elle identifier un chien ou une chaise dans le tableau de nombres d’une
                    image
                    quand l’apparence d’un chien ou d’une chaise et des objets qui les entourent peut varier infiniment
                    ? On
                    pourrait penser à écrire un programme qui fonctionnera de manière robuste pour classifier des
                    images. Ceci
                    sera tout simplement impossible. Ça prendra des milliers de ligne de code juste pour un petit
                    problème de
                    classification. La solution ultime pour faire ce travail c’est l’apprentissage machine qui va
                    entrainer la
                    machine à faire la classification.
                </p>
                <p>
                    L’apprentissage machine consiste à créer un ensemble d’algorithmes qui vont apprendre à faire la
                    classification. Ce qui nous donne un système entrainable. Un système entraînable peut être vu comme
                    une
                    boite noire avec une entrée, par exemple une image, un son, ou un texte, et une sortie qui peut
                    représenter
                    la catégorie de l’objet dans l’image, le mot prononcé, ou le sujet dont parle le texte. On parle
                    alors de
                    systèmes de classification ou de reconnaissance des formes.
                </p>
                <p>
                    L’apprentissage machine c’est elle qui anime les systèmes de toutes les grandes entreprises
                    d’Internet. Elles l’utilisent depuis longtemps pour filtrer les contenus indésirables, ordonner des
                    réponses à
                    une recherche, faire des recommandations, ou sélectionner les informations intéressantes pour chaque
                    utilisateur. Dans sa forme la plus utilisée, l’apprentissage machine est supervisé : on montre en
                    entrée de la
                    machine une photo d’un objet, par exemple une voiture, et on lui donne la sortie désirée pour une
                    voiture.
                    Puis on lui montre la photo d’un chien avec la sortie désirée pour un chien. Après chaque exemple,
                    la
                    machine ajuste ses paramètres internes de manière à rapprocher sa sortie de la sortie désirée. Après
                    avoir
                    montré à la machine des milliers ou des millions d’exemples étiquetés avec leur catégorie, la
                    machine
                    devient capable de classifier correctement la plupart d’entre eux. Mais ce qui est plus intéressant,
                    c’est
                    qu’elle peut aussi classifier correctement des images de voiture ou de chien qu’elle n’a jamais vues
                    durant
                    la phase l’apprentissage. C’est ce qu’on appelle la capacité de généralisation.
                </p>
                <p>
                    Jusqu’à récemment, les systèmes de reconnaissance des images classiques étaient composés de
                    deux blocs : un extracteur de caractéristiques (feature extractor en anglais), suivi d’un
                    classifieur entraînable
                    simple. L’extracteur de caractéristiques est programmé « à la main », et transforme le tableau de
                    nombres
                    représentant l’image en une série de nombres, un vecteur de caractéristiques, dont chacun indique la
                    présence ou l’absence d’un motif simple dans l’image. Ce vecteur est envoyé au classifieur, dont un
                    type
                    commun est le classifieur linéaire. Ce dernier calcule une somme pondérée des caractéristiques :
                    chaque
                    nombre est multiplié par un poids (positif ou négatif) avant d’être sommé. Si la somme est
                    supérieure à un
                    seuil, la classe est reconnue. Les poids forment une sorte de « prototype » pour la classe à
                    laquelle le vecteur
                    de caractéristiques est comparé. Les poids sont différents pour les classifieurs de chaque
                    catégorie, et ce
                    sont eux qui sont modifiés lors de l’apprentissage. Les premières méthodes de classification
                    linéaire
                    entraînable datent de la fin des années cinquante et sont toujours largement utilisées aujourd’hui.
                    Elles
                    prennent les deux noms de perceptron ou régression logistique.
                </p>
            </section>

            <section class="main-section conclusion" role="doc-conclusion">
                <h2 class="center">Conclusion</h2>
                <p>
                    Dans cet article nous avons présenté la notion de classification ainsi que son application dans
                    nombreux domaines notamment dans l’industrie d’internet. Nous avons vu aussi vu que pour faire de la
                    classification des images, il nous faudra utiliser des réseaux de neurones pour simplifier la tâche
                    et trouver
                    des meilleurs résultats.
                </p>
            </section>
            <!--<section class="main-section">
                    <h2>Template</h2>
                    <p>
                    </p>
                </section>-->
            <footer>
                <p>Coded by
                    <a href="https://github.com/faouziMohamed/" target="_blank" title="Facebook account">
                        FAOUZI MOHAMED
                    </a>
                </p>
            </footer>
        </article>
    </main>
    <a href="#top" class="to-top"></a>
    <script src="../js/script.js" type="module"></script>
    <noscript>
        <div id="noscript-layout">
            <p id="no-script-before-main">
                <i class="fas fa-exclamation-triangle"></i>
                <span>La page web fonctionne bien avec javascript activé</span>
            </p>
        </div>
    </noscript>

</body>


</html>