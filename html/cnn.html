<!DOCTYPE html onchange='alert("moi")'>
<html lang="fr">

<head>
    <meta charset="utf-8">
    <title>R√©seaux de neurones convolutionnels</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name='author' content="Faouzi Mohamed">
    <meta name="color-scheme" content="dark light">
    <script>
        MathJax = {
            tex: {
                inlineMath: [
                    ['$', '$'],
                    ['\\(', '\\)']
                ]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <!--<script id="MathJax-script" async src="../mathjax/es5/tex-svg-full.js"></script>-->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <link rel="stylesheet" type="text/css" href="../css/style.css">
    <noscript>
        <link rel="stylesheet" href="../css/noscript.css" />
    </noscript>

</head>

<body>
    <span id="top"></span>
    <nav id='header-nav'>
        <div id="menu-icon-wrapper">
            <i class="fas fa-bars fa-3x"></i>
        </div>
        <ul id="main-list">
            <li>
                <a href="../index.html">
                    <i id="home" class="fas fas fa-home"></i>
                    <span class="li-label">Acceuil</span>
                </a>
            </li>
            <li>
                <a href="../html/contexte.html">
                    <i class="fas fa-wallet"></i>
                    <span class="li-txt">Contexte</span>
                </a>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-layer-group"></i>
                    <span class="li-txt">Deep learning</span>
                </button>
                <ul class="submenu">
                    <li><a href="../html/nn.html">R√©seaux de neurones</a></li>
                    <li><a href="../html/cnn.html">R√©seaux de neurones convolutionnels</a></li>
                </ul>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-file-download"></i>
                    <span class="li-txt">T√©l√©charger</span>
                </button>
                <ul class="submenu">
                    <li>
                        <a href="#">Le contenu du site en pdf</a>
                    </li>
                </ul>
            </li>
        </ul>
        <label id="switch" class="switch">
            <input type="checkbox" id="slider">
            <span class="slider round"></span>
        </label>
        <a href="#" id="github">
            <i class="fab fa-github"></i>
        </a>
    </nav>
    <!--Main content-->
    <main>
        <aside id="left-aside">
            <nav id="aside-nav">
                <h1>Sommaire</h1>
                <ul id="ul-aside-nav"></ul>
            </nav>
        </aside>
        <article class="main-article" role="doc-chapter">
            <header>
                <h1>Les r√©seaux de neurones convolutionnels</h1>
            </header>
            <section class="main-section" role="doc-introduction">
                <h2>Introduction</h2>
                <p>
                    Les r√©seaux de neurones convolutifs (CNN), sont, jusqu‚Äô√†
                    <span class="dotted-border-bottom has-tooltip">maintenant<span class="tooltip">Maintenant : 2020
                        </span></span>,
                    les meilleurs mod√®les de r√©seaux de neurones pour classifier des images.
                    Elles prennent en entr√©e une image fournie sous la forme
                    d‚Äôune matrice de pixels. Cette matrice est de deux dimensions pour une image en niveau de gris. La
                    couleur est repr√©sent√©e par une troisi√®me dimension, de profondeur 3 pour repr√©senter les couleurs
                    fondamentales
                    [Rouge, Vert, Bleu} (RGB de l'anglais <span lang="en">Red, Green, Blue</span>).
                </p>
                <p>
                    Avant de continuer, rappelons-nous qu‚Äôun CNN est avant tout un r√©seau de neurone que l‚Äôon a juste
                    ajout√© un ou plusieurs couches de convolutions. Donc, les CNN respectent aussi les r√®gles d‚Äôun
                    r√©seau de neurones cit√©s sur cette
                    <a href="nn.html#titre25">section</a> du chapitre
                    <q class="quotation"><a href="nn.html">Les r√©seaux de neurones</a></q>.
                </p>

                <p>
                    Les r√©seaux de neurones convolutifs, ou CNN, ont √©t√© con√ßus pour mapper les donn√©es d'image √† une
                    variable de sortie. Ils se sont r√©v√©l√©s si efficaces qu'ils sont la m√©thode de r√©f√©rence pour tout
                    type de
                    probl√®me de pr√©diction impliquant des donn√©es d'image en entr√©e. L'avantage d'utiliser des CNN est
                    leur
                    capacit√© √† d√©velopper une repr√©sentation interne d'une image bidimensionnelle. Cela permet au mod√®le
                    d'apprendre la position et l'√©chelle dans diff√©rentes structures des donn√©es, ce qui est important
                    lorsque vous
                    travaillez avec des images.
                </p>
                <div class="list-p">
                    <p>L'avantage de CNN est que :</p>
                    <ul>
                        <li>Ils utilisent moins de param√®tres (poids) pour apprendre qu'un r√©seau enti√®rement connect√©.
                        </li>
                        <li>Ils sont con√ßus pour √™tre invariants √† la position et √† la distorsion de l'objet dans
                            l‚Äôimage.
                        </li>
                        <li> Ils apprennent et g√©n√©ralisent automatiquement les fonctionnalit√©s du domaine d'entr√©e.
                        </li>
                    </ul>
                </div>
            </section>

            <section class="main-section">
                <h2>Architecture de r√©seaux de neurone convolutionnel</h2>
                <div role="doc-pagelist" class="lisp-p">
                    <p>Il existe trois types de couches dans un r√©seau neuronal convolutif :</p>
                    <ul>
                        <li><a href="#conv">Couches convolutives</a></li>
                        <li><a href="#pooling">Couches de Pooling.</a></li>
                        <li><a href="#fully-connected">Couches enti√®rement connect√©es (fully-connected)</a></li>
                    </ul>
                </div>
                <section>
                    <h3><span id="conv"></span>Couche de convolution</h3>
                    <p>
                        Les couches convolutives sont compos√©es de <span class='bold'>filtres et de carte de
                            caract√©ristiques</span>.
                        Son but est de rep√©rer la pr√©sence d'un ensemble de caract√©ristiques dans les images re√ßues en
                        entr√©e.
                    </p>
                    <p>
                        Les filtres sont les <q class="quotation">neurones</q>
                        de la couche. Ils ont des poids d'entr√©e et produisent une valeur. La
                        taille d'entr√©e est un <span class="bold">carr√© fixe</span> appel√©
                        <strong class="bold italic"><q>patch</q></strong> ou
                        <strong class="bold italic"><q>champ r√©cepteur</q></strong>.
                        Si la couche convolutionnels est une
                        couche d'entr√©e, alors le patch d'entr√©e sera des valeurs de pixels. Si la couche est interne
                        (cach√©e), alors la
                        couche convolution prendra l'entr√©e d'une carte de caract√©ristique de la couche pr√©c√©dente.
                    </p>
                    <p>
                        La couche de convolution re√ßoit donc en entr√©e plusieurs images, et calcule la convolution de
                        chacune
                        d'entre elles avec chaque filtre. On obtient pour chaque paire (image, filtre)
                        <strong class="bold italic"><q>une carte d'activation</q></strong>, ou
                        <strong class="bold italic"><q lang="en">feature map</q></strong>,
                        qui nous indique o√π se situent <em>les <span lang="en">features</span> dans l'image</em> : plus
                        la valeur est √©lev√©e, plus
                        l'endroit correspondant dans l'image ressemble √† la <span lang="en">feature</span>.
                    </p>
                    <p>
                        Contrairement aux m√©thodes traditionnelles, les features ne sont pas pr√©d√©finies selon un
                        formalisme
                        particulier (par exemple SIFT), mais apprises par le r√©seau lors la phase d'entra√Ænement ! Les
                        noyaux des
                        filtres d√©signent les poids de la couche de convolution. Ils sont initialis√©s puis mis √† jour
                        par
                        <a href="nn.html#titre19">r√©tropropagation du gradient</a>.
                    </p>
                    <section>
                        <h4>Qu'est-ce qu'une convolution ?</h4>
                        <p role="definition">
                            Une convolution est un filtre qui passe sur une image, la traite et extrait des
                            caract√©ristiques qui
                            montrent une similitude dans l'image. Un filtre est tout simplement un ensemble d‚Äôune
                            matrice qu‚Äôon
                            appelle aussi noyau de convolution ou filtre. Ce filtre on l‚Äôapplique sur un voisinage d‚Äôune
                            image et en
                            sortie on aura une image r√©sultante diff√©rente de l‚Äôoriginal qu‚Äôon appelle <q
                                class="quotation" lang="en"> features map </q>.
                        </p>

                        <div class="figure-layout">
                            <figure id="convolution">
                                <img src="../img/convolution-light.svg" title="Filtrage d'une image par convolution"
                                    alt="Convolution" data-theme="switch" />
                                <figcaption>Application d'un filtre de convolution</figcaption>
                            </figure>
                        </div>

                        <p>
                            Appliquer donc une convolution consiste √† s√©lectionner un pixel $\boldsymbol{ùíä}$ sur une
                            image, le
                            multiplier par le
                            multiplicateur sur le filtre lui correspondant, et faire de m√™me sur chacun de ses voisins.
                            Enfin la nouvelle
                            valeur du pixel $\boldsymbol{i}$ est la somme de tous ces r√©sultats. La fonction
                            d‚Äôactivation ReLU
                            remplace donc toutes
                            les valeurs n√©gatives re√ßues en entr√©es par des z√©ros. Cela peut sembler √©trange mais voici
                            certains r√©sultats :
                        </p>
                        <div class="figure-layout slide-container" id="conv-slide">
                            <figure id="ex-conv0">
                                <img src="../img/ex-conv0.svg" alt="Extraction de caract√©ristiques">
                                <figcaption class="hide">Extraction de caract√©ristiques</figcaption>
                            </figure>
                            <figure id="ex-conv1">
                                <img src="../img/ex-conv1.svg" alt="D√©tection de lignes">
                                <figcaption class="hide">D√©tection de lignes verticales</figcaption>
                            </figure>
                            <figure id="ex-conv2">
                                <img src="../img/ex-conv2.svg" alt="D√©tection de lignes">
                                <figcaption class="hide">D√©tection de lignes horizontales</figcaption>
                            </figure>
                            <figure id="ex-conv3">
                                <img src="../img/ex-conv3.svg" alt="D√©tection de formes">
                                <figcaption class="hide">D√©tection de formes (<span lang="en">shape</span>)
                                </figcaption>
                            </figure>
                            <figure id="ex-conv4">
                                <img src="../img/ex-conv4.svg"
                                    alt="Extraction de caract√©ristiques pour la reconnaisance d'un chat">
                                <figcaption class="hide">D√©tection de formes</figcaption>
                            </figure>
                            <a class="prev" onclick="changeImg(-1)"><i class="fas fa-angle-left fa-3x"></i></a>
                            <a class="next" onclick="changeImg(1)"><i class="fas fa-angle-right fa-3x"></i></a>
                        </div>
                    </section>
                </section>
                <section>
                    <h3><span id="pooling"></span>Couche de convolution</h3>
                    <p>
                        En plus d'utiliser des convolutions, la mise en commun nous aide grandement √† d√©tecter les
                        fonctionnalit√©s. L'objectif est de r√©duire la quantit√© globale d'informations dans une image,
                        tout en
                        conservant les fonctionnalit√©s d√©tect√©es comme pr√©sentes. Une couche de Pooling est souvent
                        plac√©e entre
                        deux couches de convolution : elle re√ßoit en entr√©e plusieurs feature maps, et applique √†
                        chacune d'entre
                        elles l'op√©ration de pooling. L'op√©ration de pooling consiste √† r√©duire la taille des images,
                        tout en pr√©servant
                        leurs caract√©ristiques importantes.
                    </p>
                    <p>
                        Pour cela, on d√©coupe l'image en cellules r√©guli√®re, puis on garde au sein de chaque cellule la
                        valeur
                        maximale. En pratique, on utilise souvent des cellules carr√©es de petite taille pour ne pas
                        perdre trop
                        d'informations. Les choix les plus communs sont des cellules adjacentes de taille 2 √ó 2 pixels
                        qui ne se
                        chevauchent pas, ou des cellules de taille 3 √ó 3 pixels, distantes les unes des autres d'un pas
                        de 2 pixels
                        (qui se chevauchent donc). On obtient en sortie le m√™me nombre de feature maps qu'en entr√©e,
                        mais celles-
                        ci sont bien plus petites.
                    </p>
                    <p>
                        Il existe diff√©rents types de Pooling, mais dans notre travail, nous en utiliserons un appel√©
                        <strong class="bold">Max Pooling</strong> (<em class="italic">Pooling maximal</em>).
                    </p>
                    <p>
                        L'id√©e ici est d'it√©rer sur l'image et de regarder le pixel et ses voisins imm√©diats √† droite,
                        en dessous et √†
                        droite en dessous. Prenez le plus grand (d'o√π le nom <span class="bold">MAX</span> pooling)
                        d'entre eux et chargez-le dans la
                        nouvelle image. Ainsi, la nouvelle image sera <span class="bold">1/4 de la taille</span> de
                        l'ancienne - les dimensions sur X et Y √©tant
                        divis√©es par deux par ce processus. Les caract√©ristiques sont maintenues malgr√© cette
                        compression.
                    </p>
                    <div class="figure-layout slide-container" id="slide-pool">
                        <figure id="ex-max-pool">
                            <img src="../img/maxPooling.svg" alt="Exemple de max pooling">
                            <figcaption>Pooling maximal</figcaption>
                        </figure>

                        <figure id="gif-pooling">
                            <img src="../img/pooling.gif" title="Application d'une couche de pooling"
                                alt="Convolution.gif" />
                            <figcaption>Diminution des caract√©ristique avec un max pooling</figcaption>
                        </figure>
                    </div>
                </section>
                <section>
                    <h3><span id="fully-connected"></span>Couches enti√®rement connect√©es (fully-connected)</h3>
                    <section>
                        <p>
                            La couche fully-connected constitue toujours la derni√®re couche d'un r√©seau de neurones,
                            convolutif ou non elle n'est donc pas caract√©ristique d'un CNN. La derni√®re couche
                            <q lang="en"><a href="nn.html#titre16">fully-connected</a></q> permet
                            de classifier l'image en entr√©e du r√©seau : elle renvoie un vecteur de taille
                            $\boldsymbol{N}$,
                            o√π $\boldsymbol{N}$ est le nombre de classes dans notre probl√®me de classification d'images.
                            Chaque √©l√©ment du vecteur indique la
                            <em class="bold">probabilit√©</em> pour l'image en entr√©e <span class="bold">d'appartenir √†
                                une classe</span>.
                        </p>
                    </section>
                </section>
                <section>
                    <h3>En r√©sum√©</h3>
                    <p>
                        Le r√©seau de neurones convolutif apprend les valeurs des poids de la m√™me mani√®re qu'il apprend
                        les filtres
                        de la couche de convolution : lors de phase d'entra√Ænement, par r√©tropropagation du gradient. La
                        couche fully-connected d√©termine le lien entre la position des features dans l'image et une
                        classe.
                    </p>
                    <div class="figure-layout">
                        <figure class="resume-cnn">
                            <img src="../img/cnn-summary-light.svg" alt="R√©seaux de neurones convolutionnel"
                                data-theme="switch" />
                            <figcaption>R√©seaux de neurones convolutionnel</figcaption>
                        </figure>
                    </div>
                </section>
            </section>

            <section class="main-section">
                <h2>Choix des param√®tres</h2>
                <p>
                    Un r√©seau de neurones convolutif se distingue d'un autre par la fa√ßon dont les couches sont
                    empil√©es, mais
                    √©galement param√©tr√©es. Les couches de convolution et de pooling poss√®dent en effet des
                    hyperparam√®tres,
                    c'est-√†-dire des param√®tres dont vous devez pr√©alablement d√©finir la valeur. Les CNN utilisent plus
                    de
                    param√®tres qu'un MLP standard. M√™me si les r√®gles habituelles pour les taux d'apprentissage et des
                    constantes de r√©gularisation s'appliquent toujours, il faut prendre en consid√©ration les notions de
                    nombre de
                    filtres, leur forme et la forme du max pooling.
                </p>
                <p>
                    Les features de la couche de convolution et les poids de la couche fully-connected ne sont pas des
                    hyperparam√®tres, puisqu'ils sont appris par le r√©seau de neurones lors de la phase d‚Äôentra√Ænement !
                </p>
                <p>
                    La taille des feature maps en sortie des couches de convolution et de pooling d√©pend des
                    hyperparam√®tres.
                    Chaque image (ou feature map) est de dimensions $lxhxd$, o√π $l$ est sa largeur en pixels, $h$ sa
                    hauteur en pixels et $d$
                    le nombre de canaux ($1$ pour une image en noir et blanc, $3$ pour une image en couleurs).
                </p>

                <section>
                    <h3>La couche de convolution</h3>
                    <p>La couche de convolution poss√®de quatre hyperparam√®tres :</p>
                    <ol>
                        <li>Le nombre de filtres $\boldsymbol{k}$</li>
                        <li>La taille $\boldsymbol{f}$ des filtres : chaque filtre est de dimensions $\boldsymbol{f
                            √ó f √ó d}$ pixels.</li>
                        <li>Le pas $\boldsymbol{s}$ avec lequel on fait glisser la fen√™tre correspondant au filtre
                            sur l'image. Par exemple, un
                            pas de $\boldsymbol{1}$ signifie qu'on d√©place la fen√™tre d'un pixel √† la fois.</li>
                        <li>Le zero-padding $\boldsymbol{p}$ : on ajoute √† l'image en entr√©e de la couche un contour
                            noir d'√©paisseur $\boldsymbol{p}$ pixels.
                            Sans ce contour, les dimensions en sortie sont plus petites. Ainsi, plus on empile de
                            couches de
                            convolution avec $\boldsymbol{p = 0}$ , plus l'image en entr√©e du r√©seau r√©tr√©cit. On
                            perd donc beaucoup
                            d'informations rapidement, ce qui rend la t√¢che d'extraction de features difficile.</li>
                    </ol>

                    <div class="figure-layout">
                        <figure id="gif-conv">
                            <img src="../img/convolution.gif" title="Application d'un noyau de convolution"
                                alt="Convolution.gif" />
                            <figcaption>Application d'un filtre de convolution</figcaption>
                        </figure>
                    </div>
                </section>
                <section>
                    <h3>La couche de pooling</h3>
                    <p>La couche de pooling pr√©sente seulement deux hyperparam√®tres :</p>
                    <ol>
                        <li>La taille $\boldsymbol{f}$ des cellules : l'image est d√©coup√©e en cellules carr√©es de
                            taille $\boldsymbol{f √ó f}$ pixels</li>
                        <li>Le pas $\boldsymbol{s}$ : les cellules sont s√©par√©es les unes des autres de $\boldsymbol{s}
                            pixels$</li>
                    </ol>
                </section>
            </section>

            <section class="main-section">
                <h2>Methodes de r√©gularisation</h2>
                <p>
                    Pour ne pas tomber dans le probl√®me de sur apprentissage il y a des m√©thodes de r√©gularisation √†
                    utiliser.
                </p>
                <section>
                    <h3>Empirique</h3>
                    <section>
                        <h4>Dropout</h4>
                        <p>
                            Les couches "FC" (Fully Connected) occupent la majeure partie de la m√©moire du CNN.
                            D'ailleurs
                            le concept de FC cr√©e un probl√®me exponentiel de m√©moire appel√© "Overfitting"
                            ("sur-connexion"
                            conduisant au sur-apprentissage) ralentissant le traitement de l'information. Pour pr√©venir
                            cela, la m√©thode
                            du dropout est utilis√©e pour "√©teindre" les neurones al√©atoirement (avec une probabilit√©
                            pr√©d√©finie, souvent
                            un neurone sur deux) ainsi que les neurones p√©riph√©riques. Ainsi, avec moins de neurones, le
                            r√©seau est
                            plus r√©actif et peut donc apprendre plus rapidement. √Ä la fin de la s√©ance d'apprentissage,
                            les neurones
                            "√©teints" sont "rallum√©s" (avec leurs poids originaux). Plus la couche FC est proche de
                            l'image source,
                            moins on √©teindra de neurones. L'objectif est d'√©teindre et rallumer les neurones
                            al√©atoirement, dans le cadre
                            d'entra√Ænements successifs. Une fois les s√©ries d'entra√Ænements termin√©es, on rallume tous
                            les neurones et
                            on utilise le r√©seau comme d'habitude. Cette technique a montr√© non seulement un gain dans
                            la vitesse
                            d'apprentissage, mais en d√©connectant les neurones, on a aussi limit√© des effets marginaux,
                            rendant le r√©seau
                            plus robuste et capable de mieux g√©n√©raliser les concepts appris.
                        </p>
                    </section>
                    <section>
                        <h4>DropConnect</h4>
                        <p>Le DropConnect est une √©volution du dropout, o√π on ne va non plus √©teindre un neurone, mais
                            une
                            connexion (l'√©quivalent de la synapse), et ce de mani√®re toujours al√©atoire. Les r√©sultats
                            sont similaires
                            (rapidit√©, capacit√© de g√©n√©ralisation de l'apprentissage), mais pr√©sentent une diff√©rence au
                            niveau de
                            l'√©volution des poids des connexions. Une couche FC avec un DropConnect peut s'apparenter √†
                            une couche
                            √† connexion "diffuse".
                        </p>
                        <ul>
                            <li><span class="bold">La r√©gularisation par norme 1</span> : La sp√©cificit√© de cette
                                r√©gulation est de diminuer le poids des
                                entr√©es al√©atoires et faibles et d'augmenter le poids des entr√©es "importantes". Le
                                syst√®me devient
                                moins sensible au bruit.
                            </li>
                            <li><span class="bold">La r√©gularisation par norme 2</span> : (norme euclidienne) La
                                sp√©cificit√© de cette r√©gulation est de
                                diminuer le poids des entr√©es fortes, et de forcer le neurone √† plus prendre en compte
                                les entr√©es de
                                poids faible.
                            </li>
                        </ul>
                        <p>
                            Les r√©gularisations par norme 1 et norme 2 peuvent √™tre combin√©es : c'est la "r√©gularisation
                            de r√©seau √©lastique" (<span class="bold">Elastic net regulation</span>).
                        </p>
                    </section>
                </section>

                <section>
                    <h3>Explicite</h3>
                    <section>
                        <h4>Taille du r√©seau</h4>
                        <p>
                            La mani√®re la plus simple de limiter le sur apprentissage est de limiter le nombre de
                            couches du r√©seau et
                            de lib√©rer les param√®tres libres (connexions) du r√©seau. Ceci r√©duit directement la
                            puissance et le potentiel
                            pr√©dictif du r√©seau. C'est √©quivalent √† avoir une "norme z√©ro".
                        </p>
                    </section>

                    <section>
                        <h4>D√©gradation du poids</h4>
                        <p>
                            Le concept est de consid√©rer le vecteur des poids d'un neurone (liste des poids associ√©s aux
                            signaux
                            entrants), et de lui rajouter un vecteur d'erreur proportionnel √† la somme des poids (norme
                            1) ou du carr√©
                            des poids (norme 2 ou euclidienne). Ce vecteur d'erreur peut ensuite √™tre multipli√© par un
                            coefficient de
                            proportionnalit√© que l'on va augmenter pour p√©naliser davantage les vecteurs de poids forts.
                        </p>
                    </section>
                </section>
            </section>

            <section id class="main-section conclusion" role="doc-conclusion">
                <h2 class="center">Conclusion</h2>
                <p>
                    Dans ce chapitre nous avons √©voqu√© les r√©seaux de neurones du type Feed-forward aussi connu sous
                    le nom de R√©seau de type perceptron. Ainsi, nous nous sommes un peu attard√©s sur les perceptrons
                    multicouches qui comporte des neurones compl√®tement connect√©s. Nous avons aussi parler de r√©seaux
                    neuronal convolutifs. Ces r√©seaux sont capables d‚Äôextraire des caract√©ristiques d‚Äôimages pr√©sent√©es
                    en
                    entr√©e et de classifier ces caract√©ristiques. Le succ√®s des CNN ces derni√®res ann√©es d√©pend
                    principalement
                    des trois piliers suivants : donn√©es, mod√®le et puissance de calcul.
                </p>

                <p>
                    Les r√©seaux de neurones convolutionnels pr√©sentent cependant un certain nombre de limitations, en
                    premier lieu, les hyper param√®tres du r√©seau sont difficiles √† √©valuer a priori. En effet, le nombre
                    de couches,
                    les nombre de neurones par couche ou encore les diff√©rentes connexions entre couches sont des
                    √©l√©ments
                    cruciaux et essentiellement d√©termin√©s par une bonne intuition ou par une succession de tests/calcul
                    d‚Äôerreurs (ce qui est co√ªteux en temps). Le nombre d‚Äô√©chantillons d‚Äôapprentissage est √©galement un
                    √©l√©ment
                    d√©terminant, et il arrive souvent que celui‚Äìci soit trop faible en comparaison du nombre de
                    param√®tres
                    (poids) du r√©seau. Des solutions existent comme augmenter artificiellement leur nombre ou encore en
                    r√©duisant le nombre de param√®tres libres (en r√©alisant un pr√©apprentissage des premi√®res couches par
                    exemple).
                </p>

                <p>
                    Dans le prochain chapitre, nous allons mettre en pratique les CNN avec l‚Äôimpl√©mentation de notre
                    propre
                    mod√®le de deep learning.
                </p>

            </section>
            <footer class="hidden">
                <p>Coded by
                    <a href="https://github.com/faouziMohamed/" target="_blank" title="Facebook account">
                        FAOUZI MOHAMED
                    </a>
                </p>
            </footer>
        </article>
    </main>
    <a href="#top" class="to-top"></a>
    <script src="../js/script.mjs" defer type="module"></script>
    <noscript>
        <div id="noscript-layout">
            <p id="no-script-before-main">
                <i class="fas fa-exclamation-triangle"></i>
                <span>La page web fonctionne bien avec javascript activ√©</span>
            </p>
        </div>
    </noscript>
</body>


</html>