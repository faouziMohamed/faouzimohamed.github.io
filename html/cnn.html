<!DOCTYPE html onchange='alert("moi")'>
<html lang="fr">

<head>
    <meta charset="utf-8">
    <title>Réseaux de neurones convolutionnels</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name='author' content="Faouzi Mohamed">
    <meta name="color-scheme" content="dark light">
    <script>
        MathJax = {
            tex: {
                inlineMath: [
                    ['$', '$'],
                    ['\\(', '\\)']
                ]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <!--<script id="MathJax-script" async src="../mathjax/es5/tex-svg-full.js"></script>-->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
    <link rel="stylesheet" type="text/css" href="../css/style.css">
    <noscript>
        <link rel="stylesheet" href="../css/noscript.css" />
    </noscript>

</head>

<body>
    <span id="top"></span>
    <nav id='header-nav'>
        <div id="menu-icon-wrapper">
            <i class="fas fa-bars fa-3x"></i>
        </div>
        <ul id="main-list">
            <li>
                <a href="../index.html">
                    <i id="home" class="fas fas fa-home"></i>
                    <span class="li-label">Acceuil</span>
                </a>
            </li>
            <li>
                <a href="../html/contexte.html">
                    <i class="fas fa-wallet"></i>
                    <span class="li-txt">Contexte</span>
                </a>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-layer-group"></i>
                    <span class="li-txt">Deep learning</span>
                </button>
                <ul class="submenu">
                    <li><a href="../html/nn.html">Réseaux de neurones</a></li>
                    <li><a href="../html/cnn.html">Réseaux de neurones convolutionnels</a></li>
                </ul>
            </li>
            <li class="submenu-parent">
                <button type="button">
                    <i class="fas fa-file-download"></i>
                    <span class="li-txt">Télécharger</span>
                </button>
                <ul class="submenu">
                    <li>
                        <a href="#">Le contenu du site en pdf</a>
                    </li>
                </ul>
            </li>
        </ul>
        <label id="switch" class="switch">
            <input type="checkbox" id="slider">
            <span class="slider round"></span>
        </label>
        <a href="#" id="github">
            <i class="fab fa-github"></i>
        </a>
    </nav>
    <!--Main content-->
    <main>
        <aside id="left-aside">
            <nav id="aside-nav">
                <h1>Sommaire</h1>
                <ul id="ul-aside-nav"></ul>
            </nav>
        </aside>
        <article class="main-article" role="doc-chapter">
            <header>
                <h1>Les réseaux de neurones convolutionnels</h1>
            </header>
            <section class="main-section" role="doc-introduction">
                <h2>Introduction</h2>
                <p>
                    Les réseaux de neurones convolutifs (CNN), sont, jusqu’à
                    <span class="dotted-border-bottom has-tooltip">maintenant<span class="tooltip">Maintenant : 2020
                        </span></span>,
                    les meilleurs modèles de réseaux de neurones pour classifier des images.
                    Elles prennent en entrée une image fournie sous la forme
                    d’une matrice de pixels. Cette matrice est de deux dimensions pour une image en niveau de gris. La
                    couleur est représentée par une troisième dimension, de profondeur 3 pour représenter les couleurs
                    fondamentales
                    [Rouge, Vert, Bleu} (RGB de l'anglais <span lang="en">Red, Green, Blue</span>).
                </p>
                <p>
                    Avant de continuer, rappelons-nous qu’un CNN est avant tout un réseau de neurone que l’on a juste
                    ajouté un ou plusieurs couches de convolutions. Donc, les CNN respectent aussi les règles d’un
                    réseau de neurones cités sur cette
                    <a href="nn.html#titre25">section</a> du chapitre
                    <q class="quotation"><a href="nn.html">Les réseaux de neurones</a></q>.
                </p>

                <p>
                    Les réseaux de neurones convolutifs, ou CNN, ont été conçus pour mapper les données d'image à une
                    variable de sortie. Ils se sont révélés si efficaces qu'ils sont la méthode de référence pour tout
                    type de
                    problème de prédiction impliquant des données d'image en entrée. L'avantage d'utiliser des CNN est
                    leur
                    capacité à développer une représentation interne d'une image bidimensionnelle. Cela permet au modèle
                    d'apprendre la position et l'échelle dans différentes structures des données, ce qui est important
                    lorsque vous
                    travaillez avec des images.
                </p>
                <div class="list-p">
                    <p>L'avantage de CNN est que :</p>
                    <ul>
                        <li>Ils utilisent moins de paramètres (poids) pour apprendre qu'un réseau entièrement connecté.
                        </li>
                        <li>Ils sont conçus pour être invariants à la position et à la distorsion de l'objet dans
                            l’image.
                        </li>
                        <li> Ils apprennent et généralisent automatiquement les fonctionnalités du domaine d'entrée.
                        </li>
                    </ul>
                </div>
            </section>

            <section class="main-section">
                <h2>Architecture de réseaux de neurone convolutionnel</h2>
                <div role="doc-pagelist" class="lisp-p">
                    <p>Il existe trois types de couches dans un réseau neuronal convolutif :</p>
                    <ul>
                        <li><a href="#conv">Couches convolutives</a></li>
                        <li><a href="#pooling">Couches de Pooling.</a></li>
                        <li><a href="#fully-connected">Couches entièrement connectées (fully-connected)</a></li>
                    </ul>
                </div>
                <section>
                    <h3><span id="conv"></span>Couche de convolution</h3>
                    <p>
                        Les couches convolutives sont composées de <span class='bold'>filtres et de carte de
                            caractéristiques</span>.
                        Son but est de repérer la présence d'un ensemble de caractéristiques dans les images reçues en
                        entrée.
                    </p>
                    <p>
                        Les filtres sont les <q class="quotation">neurones</q>
                        de la couche. Ils ont des poids d'entrée et produisent une valeur. La
                        taille d'entrée est un <span class="bold">carré fixe</span> appelé
                        <strong class="bold italic"><q>patch</q></strong> ou
                        <strong class="bold italic"><q>champ récepteur</q></strong>.
                        Si la couche convolutionnels est une
                        couche d'entrée, alors le patch d'entrée sera des valeurs de pixels. Si la couche est interne
                        (cachée), alors la
                        couche convolution prendra l'entrée d'une carte de caractéristique de la couche précédente.
                    </p>
                    <p>
                        La couche de convolution reçoit donc en entrée plusieurs images, et calcule la convolution de
                        chacune
                        d'entre elles avec chaque filtre. On obtient pour chaque paire (image, filtre)
                        <strong class="bold italic"><q>une carte d'activation</q></strong>, ou
                        <strong class="bold italic"><q lang="en">feature map</q></strong>,
                        qui nous indique où se situent <em>les <span lang="en">features</span> dans l'image</em> : plus
                        la valeur est élevée, plus
                        l'endroit correspondant dans l'image ressemble à la <span lang="en">feature</span>.
                    </p>
                    <p>
                        Contrairement aux méthodes traditionnelles, les features ne sont pas prédéfinies selon un
                        formalisme
                        particulier (par exemple SIFT), mais apprises par le réseau lors la phase d'entraînement ! Les
                        noyaux des
                        filtres désignent les poids de la couche de convolution. Ils sont initialisés puis mis à jour
                        par
                        <a href="nn.html#titre19">rétropropagation du gradient</a>.
                    </p>
                    <section>
                        <h4>Qu'est-ce qu'une convolution ?</h4>
                        <p role="definition">
                            Une convolution est un filtre qui passe sur une image, la traite et extrait des
                            caractéristiques qui
                            montrent une similitude dans l'image. Un filtre est tout simplement un ensemble d’une
                            matrice qu’on
                            appelle aussi noyau de convolution ou filtre. Ce filtre on l’applique sur un voisinage d’une
                            image et en
                            sortie on aura une image résultante différente de l’original qu’on appelle <q
                                class="quotation" lang="en"> features map </q>.
                        </p>

                        <div class="figure-layout">
                            <figure id="convolution">
                                <img src="../img/convolution-light.svg" title="Filtrage d'une image par convolution"
                                    alt="Convolution" data-theme="switch" />
                                <figcaption>Application d'un filtre de convolution</figcaption>
                            </figure>
                        </div>

                        <p>
                            Appliquer donc une convolution consiste à sélectionner un pixel $\boldsymbol{𝒊}$ sur une
                            image, le
                            multiplier par le
                            multiplicateur sur le filtre lui correspondant, et faire de même sur chacun de ses voisins.
                            Enfin la nouvelle
                            valeur du pixel $\boldsymbol{i}$ est la somme de tous ces résultats. La fonction
                            d’activation ReLU
                            remplace donc toutes
                            les valeurs négatives reçues en entrées par des zéros. Cela peut sembler étrange mais voici
                            certains résultats :
                        </p>
                        <div class="figure-layout slide-container" id="conv-slide">
                            <figure id="ex-conv0">
                                <img src="../img/ex-conv0.svg" alt="Extraction de caractéristiques">
                                <figcaption class="hide">Extraction de caractéristiques</figcaption>
                            </figure>
                            <figure id="ex-conv1">
                                <img src="../img/ex-conv1.svg" alt="Détection de lignes">
                                <figcaption class="hide">Détection de lignes verticales</figcaption>
                            </figure>
                            <figure id="ex-conv2">
                                <img src="../img/ex-conv2.svg" alt="Détection de lignes">
                                <figcaption class="hide">Détection de lignes horizontales</figcaption>
                            </figure>
                            <figure id="ex-conv3">
                                <img src="../img/ex-conv3.svg" alt="Détection de formes">
                                <figcaption class="hide">Détection de formes (<span lang="en">shape</span>)
                                </figcaption>
                            </figure>
                            <figure id="ex-conv4">
                                <img src="../img/ex-conv4.svg"
                                    alt="Extraction de caractéristiques pour la reconnaisance d'un chat">
                                <figcaption class="hide">Détection de formes</figcaption>
                            </figure>
                            <a class="prev" onclick="changeImg(-1)"><i class="fas fa-angle-left fa-3x"></i></a>
                            <a class="next" onclick="changeImg(1)"><i class="fas fa-angle-right fa-3x"></i></a>
                        </div>
                    </section>
                </section>
                <section>
                    <h3><span id="pooling"></span>Couche de convolution</h3>
                    <p>
                        En plus d'utiliser des convolutions, la mise en commun nous aide grandement à détecter les
                        fonctionnalités. L'objectif est de réduire la quantité globale d'informations dans une image,
                        tout en
                        conservant les fonctionnalités détectées comme présentes. Une couche de Pooling est souvent
                        placée entre
                        deux couches de convolution : elle reçoit en entrée plusieurs feature maps, et applique à
                        chacune d'entre
                        elles l'opération de pooling. L'opération de pooling consiste à réduire la taille des images,
                        tout en préservant
                        leurs caractéristiques importantes.
                    </p>
                    <p>
                        Pour cela, on découpe l'image en cellules régulière, puis on garde au sein de chaque cellule la
                        valeur
                        maximale. En pratique, on utilise souvent des cellules carrées de petite taille pour ne pas
                        perdre trop
                        d'informations. Les choix les plus communs sont des cellules adjacentes de taille 2 × 2 pixels
                        qui ne se
                        chevauchent pas, ou des cellules de taille 3 × 3 pixels, distantes les unes des autres d'un pas
                        de 2 pixels
                        (qui se chevauchent donc). On obtient en sortie le même nombre de feature maps qu'en entrée,
                        mais celles-
                        ci sont bien plus petites.
                    </p>
                    <p>
                        Il existe différents types de Pooling, mais dans notre travail, nous en utiliserons un appelé
                        <strong class="bold">Max Pooling</strong> (<em class="italic">Pooling maximal</em>).
                    </p>
                    <p>
                        L'idée ici est d'itérer sur l'image et de regarder le pixel et ses voisins immédiats à droite,
                        en dessous et à
                        droite en dessous. Prenez le plus grand (d'où le nom <span class="bold">MAX</span> pooling)
                        d'entre eux et chargez-le dans la
                        nouvelle image. Ainsi, la nouvelle image sera <span class="bold">1/4 de la taille</span> de
                        l'ancienne - les dimensions sur X et Y étant
                        divisées par deux par ce processus. Les caractéristiques sont maintenues malgré cette
                        compression.
                    </p>
                    <div class="figure-layout slide-container" id="slide-pool">
                        <figure id="ex-max-pool">
                            <img src="../img/maxPooling.svg" alt="Exemple de max pooling">
                            <figcaption>Pooling maximal</figcaption>
                        </figure>

                        <figure id="gif-pooling">
                            <img src="../img/pooling.gif" title="Application d'une couche de pooling"
                                alt="Convolution.gif" />
                            <figcaption>Diminution des caractéristique avec un max pooling</figcaption>
                        </figure>
                    </div>
                </section>
                <section>
                    <h3><span id="fully-connected"></span>Couches entièrement connectées (fully-connected)</h3>
                    <section>
                        <p>
                            La couche fully-connected constitue toujours la dernière couche d'un réseau de neurones,
                            convolutif ou non elle n'est donc pas caractéristique d'un CNN. La dernière couche
                            <q lang="en"><a href="nn.html#titre16">fully-connected</a></q> permet
                            de classifier l'image en entrée du réseau : elle renvoie un vecteur de taille
                            $\boldsymbol{N}$,
                            où $\boldsymbol{N}$ est le nombre de classes dans notre problème de classification d'images.
                            Chaque élément du vecteur indique la
                            <em class="bold">probabilité</em> pour l'image en entrée <span class="bold">d'appartenir à
                                une classe</span>.
                        </p>
                    </section>
                </section>
                <section>
                    <h3>En résumé</h3>
                    <p>
                        Le réseau de neurones convolutif apprend les valeurs des poids de la même manière qu'il apprend
                        les filtres
                        de la couche de convolution : lors de phase d'entraînement, par rétropropagation du gradient. La
                        couche fully-connected détermine le lien entre la position des features dans l'image et une
                        classe.
                    </p>
                    <div class="figure-layout">
                        <figure class="resume-cnn">
                            <img src="../img/cnn-summary-light.svg" alt="Réseaux de neurones convolutionnel"
                                data-theme="switch" />
                            <figcaption>Réseaux de neurones convolutionnel</figcaption>
                        </figure>
                    </div>
                </section>
            </section>

            <section class="main-section">
                <h2>Choix des paramètres</h2>
                <p>
                    Un réseau de neurones convolutif se distingue d'un autre par la façon dont les couches sont
                    empilées, mais
                    également paramétrées. Les couches de convolution et de pooling possèdent en effet des
                    hyperparamètres,
                    c'est-à-dire des paramètres dont vous devez préalablement définir la valeur. Les CNN utilisent plus
                    de
                    paramètres qu'un MLP standard. Même si les règles habituelles pour les taux d'apprentissage et des
                    constantes de régularisation s'appliquent toujours, il faut prendre en considération les notions de
                    nombre de
                    filtres, leur forme et la forme du max pooling.
                </p>
                <p>
                    Les features de la couche de convolution et les poids de la couche fully-connected ne sont pas des
                    hyperparamètres, puisqu'ils sont appris par le réseau de neurones lors de la phase d’entraînement !
                </p>
                <p>
                    La taille des feature maps en sortie des couches de convolution et de pooling dépend des
                    hyperparamètres.
                    Chaque image (ou feature map) est de dimensions $lxhxd$, où $l$ est sa largeur en pixels, $h$ sa
                    hauteur en pixels et $d$
                    le nombre de canaux ($1$ pour une image en noir et blanc, $3$ pour une image en couleurs).
                </p>

                <section>
                    <h3>La couche de convolution</h3>
                    <p>La couche de convolution possède quatre hyperparamètres :</p>
                    <ol>
                        <li>Le nombre de filtres $\boldsymbol{k}$</li>
                        <li>La taille $\boldsymbol{f}$ des filtres : chaque filtre est de dimensions $\boldsymbol{f
                            × f × d}$ pixels.</li>
                        <li>Le pas $\boldsymbol{s}$ avec lequel on fait glisser la fenêtre correspondant au filtre
                            sur l'image. Par exemple, un
                            pas de $\boldsymbol{1}$ signifie qu'on déplace la fenêtre d'un pixel à la fois.</li>
                        <li>Le zero-padding $\boldsymbol{p}$ : on ajoute à l'image en entrée de la couche un contour
                            noir d'épaisseur $\boldsymbol{p}$ pixels.
                            Sans ce contour, les dimensions en sortie sont plus petites. Ainsi, plus on empile de
                            couches de
                            convolution avec $\boldsymbol{p = 0}$ , plus l'image en entrée du réseau rétrécit. On
                            perd donc beaucoup
                            d'informations rapidement, ce qui rend la tâche d'extraction de features difficile.</li>
                    </ol>

                    <div class="figure-layout">
                        <figure id="gif-conv">
                            <img src="../img/convolution.gif" title="Application d'un noyau de convolution"
                                alt="Convolution.gif" />
                            <figcaption>Application d'un filtre de convolution</figcaption>
                        </figure>
                    </div>
                </section>
                <section>
                    <h3>La couche de pooling</h3>
                    <p>La couche de pooling présente seulement deux hyperparamètres :</p>
                    <ol>
                        <li>La taille $\boldsymbol{f}$ des cellules : l'image est découpée en cellules carrées de
                            taille $\boldsymbol{f × f}$ pixels</li>
                        <li>Le pas $\boldsymbol{s}$ : les cellules sont séparées les unes des autres de $\boldsymbol{s}
                            pixels$</li>
                    </ol>
                </section>
            </section>

            <section class="main-section">
                <h2>Methodes de régularisation</h2>
                <p>
                    Pour ne pas tomber dans le problème de sur apprentissage il y a des méthodes de régularisation à
                    utiliser.
                </p>
                <section>
                    <h3>Empirique</h3>
                    <section>
                        <h4>Dropout</h4>
                        <p>
                            Les couches "FC" (Fully Connected) occupent la majeure partie de la mémoire du CNN.
                            D'ailleurs
                            le concept de FC crée un problème exponentiel de mémoire appelé "Overfitting"
                            ("sur-connexion"
                            conduisant au sur-apprentissage) ralentissant le traitement de l'information. Pour prévenir
                            cela, la méthode
                            du dropout est utilisée pour "éteindre" les neurones aléatoirement (avec une probabilité
                            prédéfinie, souvent
                            un neurone sur deux) ainsi que les neurones périphériques. Ainsi, avec moins de neurones, le
                            réseau est
                            plus réactif et peut donc apprendre plus rapidement. À la fin de la séance d'apprentissage,
                            les neurones
                            "éteints" sont "rallumés" (avec leurs poids originaux). Plus la couche FC est proche de
                            l'image source,
                            moins on éteindra de neurones. L'objectif est d'éteindre et rallumer les neurones
                            aléatoirement, dans le cadre
                            d'entraînements successifs. Une fois les séries d'entraînements terminées, on rallume tous
                            les neurones et
                            on utilise le réseau comme d'habitude. Cette technique a montré non seulement un gain dans
                            la vitesse
                            d'apprentissage, mais en déconnectant les neurones, on a aussi limité des effets marginaux,
                            rendant le réseau
                            plus robuste et capable de mieux généraliser les concepts appris.
                        </p>
                    </section>
                    <section>
                        <h4>DropConnect</h4>
                        <p>Le DropConnect est une évolution du dropout, où on ne va non plus éteindre un neurone, mais
                            une
                            connexion (l'équivalent de la synapse), et ce de manière toujours aléatoire. Les résultats
                            sont similaires
                            (rapidité, capacité de généralisation de l'apprentissage), mais présentent une différence au
                            niveau de
                            l'évolution des poids des connexions. Une couche FC avec un DropConnect peut s'apparenter à
                            une couche
                            à connexion "diffuse".
                        </p>
                        <ul>
                            <li><span class="bold">La régularisation par norme 1</span> : La spécificité de cette
                                régulation est de diminuer le poids des
                                entrées aléatoires et faibles et d'augmenter le poids des entrées "importantes". Le
                                système devient
                                moins sensible au bruit.
                            </li>
                            <li><span class="bold">La régularisation par norme 2</span> : (norme euclidienne) La
                                spécificité de cette régulation est de
                                diminuer le poids des entrées fortes, et de forcer le neurone à plus prendre en compte
                                les entrées de
                                poids faible.
                            </li>
                        </ul>
                        <p>
                            Les régularisations par norme 1 et norme 2 peuvent être combinées : c'est la "régularisation
                            de réseau élastique" (<span class="bold">Elastic net regulation</span>).
                        </p>
                    </section>
                </section>

                <section>
                    <h3>Explicite</h3>
                    <section>
                        <h4>Taille du réseau</h4>
                        <p>
                            La manière la plus simple de limiter le sur apprentissage est de limiter le nombre de
                            couches du réseau et
                            de libérer les paramètres libres (connexions) du réseau. Ceci réduit directement la
                            puissance et le potentiel
                            prédictif du réseau. C'est équivalent à avoir une "norme zéro".
                        </p>
                    </section>

                    <section>
                        <h4>Dégradation du poids</h4>
                        <p>
                            Le concept est de considérer le vecteur des poids d'un neurone (liste des poids associés aux
                            signaux
                            entrants), et de lui rajouter un vecteur d'erreur proportionnel à la somme des poids (norme
                            1) ou du carré
                            des poids (norme 2 ou euclidienne). Ce vecteur d'erreur peut ensuite être multiplié par un
                            coefficient de
                            proportionnalité que l'on va augmenter pour pénaliser davantage les vecteurs de poids forts.
                        </p>
                    </section>
                </section>
            </section>

            <section id class="main-section conclusion" role="doc-conclusion">
                <h2 class="center">Conclusion</h2>
                <p>
                    Dans ce chapitre nous avons évoqué les réseaux de neurones du type Feed-forward aussi connu sous
                    le nom de Réseau de type perceptron. Ainsi, nous nous sommes un peu attardés sur les perceptrons
                    multicouches qui comporte des neurones complètement connectés. Nous avons aussi parler de réseaux
                    neuronal convolutifs. Ces réseaux sont capables d’extraire des caractéristiques d’images présentées
                    en
                    entrée et de classifier ces caractéristiques. Le succès des CNN ces dernières années dépend
                    principalement
                    des trois piliers suivants : données, modèle et puissance de calcul.
                </p>

                <p>
                    Les réseaux de neurones convolutionnels présentent cependant un certain nombre de limitations, en
                    premier lieu, les hyper paramètres du réseau sont difficiles à évaluer a priori. En effet, le nombre
                    de couches,
                    les nombre de neurones par couche ou encore les différentes connexions entre couches sont des
                    éléments
                    cruciaux et essentiellement déterminés par une bonne intuition ou par une succession de tests/calcul
                    d’erreurs (ce qui est coûteux en temps). Le nombre d’échantillons d’apprentissage est également un
                    élément
                    déterminant, et il arrive souvent que celui–ci soit trop faible en comparaison du nombre de
                    paramètres
                    (poids) du réseau. Des solutions existent comme augmenter artificiellement leur nombre ou encore en
                    réduisant le nombre de paramètres libres (en réalisant un préapprentissage des premières couches par
                    exemple).
                </p>

                <p>
                    Dans le prochain chapitre, nous allons mettre en pratique les CNN avec l’implémentation de notre
                    propre
                    modèle de deep learning.
                </p>

            </section>
            <footer class="hidden">
                <p>Coded by
                    <a href="https://github.com/faouziMohamed/" target="_blank" title="Facebook account">
                        FAOUZI MOHAMED
                    </a>
                </p>
            </footer>
        </article>
    </main>
    <a href="#top" class="to-top"></a>
    <script src="../js/script.mjs" defer type="module"></script>
    <noscript>
        <div id="noscript-layout">
            <p id="no-script-before-main">
                <i class="fas fa-exclamation-triangle"></i>
                <span>La page web fonctionne bien avec javascript activé</span>
            </p>
        </div>
    </noscript>
</body>


</html>